{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294b5552",
   "metadata": {},
   "source": [
    "## Este código é somente uma ferramenta de validação, para garantir que não foram coletados acórdãos duplicados nem que há arquivos faltantes ou em excesso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d253b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import Set\n",
    "import polars as pl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30730e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_names(directory: str) -> Set[str]:\n",
    "    \"\"\"Retorna nomes dos arquivos PDF sem extensão.\"\"\"\n",
    "    return {os.path.splitext(f)[0] for f in os.listdir(directory) if f.lower().endswith('.pdf')}\n",
    "\n",
    "def get_csv_ids(csv_path: str) -> Set[str]:\n",
    "    \"\"\"Retorna IDs únicos do CSV como strings.\"\"\"\n",
    "    return set(pd.read_csv(csv_path)['id'].dropna().astype(str))\n",
    "\n",
    "def validate_files():\n",
    "    \"\"\"Valida se todos os IDs do CSV têm arquivos PDF correspondentes.\"\"\"\n",
    "    pdf_directory = \"STF FINAL\"\n",
    "    csv_file = \"jurisprudencia_data.csv\"\n",
    "    \n",
    "    pdf_files = get_pdf_names(pdf_directory)\n",
    "    csv_ids = get_csv_ids(csv_file)\n",
    "    missing_files = csv_ids - pdf_files\n",
    "    extra_files = pdf_files - csv_ids\n",
    "    \n",
    "    print(f\"Total de IDs no CSV: {len(csv_ids)}\")\n",
    "    print(f\"Total de PDFs na pasta: {len(pdf_files)}\")\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"\\nArquivos faltantes ({len(missing_files)}):\")\n",
    "        for file_id in sorted(missing_files):\n",
    "            print(f\"  {file_id}\")\n",
    "    else:\n",
    "        print(\"Todos os documentos do CSV estão presentes.\")\n",
    "    \n",
    "    if extra_files:\n",
    "        print(f\"\\nArquivos extras na pasta ({len(extra_files)}):\")\n",
    "        for file_id in sorted(extra_files):\n",
    "            print(f\"  {file_id}\")\n",
    "    else:\n",
    "        print(\"Nenhum arquivo extra na pasta.\")\n",
    "\n",
    "def check_duplicates():\n",
    "    \"\"\"Verifica se existem valores duplicados na segunda coluna do arquivo parquet.\"\"\"\n",
    "    parquet_file = \"documentos.parquet\"\n",
    "    \n",
    "    if not os.path.exists(parquet_file):\n",
    "        print(f\"Arquivo não encontrado: {parquet_file}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        df = pl.read_parquet(parquet_file)\n",
    "        second_column_name = df.columns[1]\n",
    "        \n",
    "        total_values = df.height\n",
    "        unique_values = df[second_column_name].n_unique()\n",
    "        duplicated_values = total_values - unique_values\n",
    "        \n",
    "        print(f\"Coluna analisada: {second_column_name}\")\n",
    "        print(f\"Total de valores: {total_values}\")\n",
    "        print(f\"Valores únicos: {unique_values}\")\n",
    "        \n",
    "        if duplicated_values > 0:\n",
    "            print(f\"Valores duplicados encontrados: {duplicated_values}\")\n",
    "            \n",
    "            # Encontra linhas com valores duplicados na segunda coluna\n",
    "            duplicated_df = df.filter(\n",
    "                pl.col(second_column_name).is_in(\n",
    "                    df.group_by(second_column_name)\n",
    "                    .count()\n",
    "                    .filter(pl.col(\"count\") > 1)[second_column_name]\n",
    "                )\n",
    "            ).sort(second_column_name)\n",
    "            \n",
    "            print(f\"\\nInício dos textos duplicados:\")\n",
    "            for row in duplicated_df.iter_rows(named=True):\n",
    "                text_preview = str(row[second_column_name])[:100] + \"...\" if len(str(row[second_column_name])) > 100 else str(row[second_column_name])\n",
    "                print(f\"ID: {row[df.columns[0]]} | Texto: {text_preview}\")\n",
    "        else:\n",
    "            print(\"Nenhum valor duplicado encontrado na segunda coluna.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler arquivo parquet: {str(e)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d0ba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de IDs no CSV: 1108\n",
      "Total de PDFs na pasta: 1108\n",
      "Todos os documentos do CSV estão presentes.\n",
      "Nenhum arquivo extra na pasta.\n"
     ]
    }
   ],
   "source": [
    "validate_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna analisada: texto_completo\n",
      "Total de valores: 1084\n",
      "Valores únicos: 1084\n",
      "Nenhum valor duplicado encontrado na segunda coluna.\n"
     ]
    }
   ],
   "source": [
    "check_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
