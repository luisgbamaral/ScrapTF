"""
Exemplo completo de uso do STF Scraper.
"""

import os
from pathlib import Path
from stf_scraper import STFScraper
from stf_scraper.config import STFScraperConfig, DEVELOPMENT_CONFIG, PRODUCTION_CONFIG


def exemplo_basico():
    """Exemplo bÃ¡sico de uso."""
    print("=== Exemplo BÃ¡sico ===")

    # Lista de processos para teste
    processos = [
        "0001234-56.2023.1.00.0000",  # Formato vÃ¡lido para teste
        "0009876-54.2022.1.00.0000"
    ]

    # ConfiguraÃ§Ã£o bÃ¡sica
    scraper = STFScraper(
        process_list=processos,
        output_path="exemplo_basico.parquet",
        batch_size=10,
        max_retries=3
    )

    try:
        resultado = scraper.run()
        print(f"âœ… Processamento concluÃ­do!")
        print(f"ğŸ“Š Total de registros: {resultado.get('total_records', 0)}")
        print(f"ğŸ“ˆ Taxa de sucesso: {resultado.get('success_rate', 0):.1f}%")

    except Exception as e:
        print(f"âŒ Erro: {e}")


def exemplo_com_s3():
    """Exemplo usando Amazon S3."""
    print("\n=== Exemplo com S3 ===")

    # Verificar se credenciais AWS estÃ£o configuradas
    if not (os.getenv('AWS_ACCESS_KEY_ID') and os.getenv('AWS_SECRET_ACCESS_KEY')):
        print("âš ï¸  Credenciais AWS nÃ£o configuradas. Pulando exemplo S3.")
        return

    processos = [
        "0001234-56.2023.1.00.0000",
        "0009876-54.2022.1.00.0000"
    ]

    scraper = STFScraper(
        process_list=processos,
        output_path="s3://meu-bucket-exemplo/processos_stf.parquet",
        batch_size=50,
        max_retries=5,
        log_level="INFO"
    )

    try:
        resultado = scraper.run()
        print(f"âœ… Dados salvos no S3!")
        print(f"ğŸ“ Arquivo: {resultado.get('output_path')}")
        print(f"ğŸ’¾ Tamanho: {resultado.get('file_size_mb', 0):.2f} MB")

    except Exception as e:
        print(f"âŒ Erro S3: {e}")


def exemplo_com_proxies():
    """Exemplo usando proxies."""
    print("\n=== Exemplo com Proxies ===")

    # Lista de proxies de exemplo (substitua por proxies reais)
    proxies = [
        "proxy1.exemplo.com:8080",
        "proxy2.exemplo.com:8080"
    ]

    processos = [
        "0001234-56.2023.1.00.0000"
    ]

    scraper = STFScraper(
        process_list=processos,
        output_path="exemplo_proxies.parquet",
        use_proxies=True,
        proxy_list=proxies,
        max_workers=3,
        rate_limit_delay=2.0
    )

    try:
        resultado = scraper.run()
        print(f"âœ… Scraping com proxies concluÃ­do!")
        print(f"ğŸ”„ Tentativas de retry: {resultado.get('retries', 0)}")

    except Exception as e:
        print(f"âŒ Erro com proxies: {e}")


def exemplo_configuracao_avancada():
    """Exemplo com configuraÃ§Ã£o avanÃ§ada."""
    print("\n=== ConfiguraÃ§Ã£o AvanÃ§ada ===")

    # Carrega configuraÃ§Ã£o do ambiente
    config = STFScraperConfig.from_env()

    # Mescla com configuraÃ§Ã£o de produÃ§Ã£o
    config.update(PRODUCTION_CONFIG)

    processos = [
        "0001234-56.2023.1.00.0000",
        "0009876-54.2022.1.00.0000",
        "0005555-55.2021.1.00.0000"
    ]

    scraper = STFScraper(
        process_list=processos,
        output_path="exemplo_avancado.parquet",
        **config  # Passa todas as configuraÃ§Ãµes
    )

    try:
        resultado = scraper.run()
        print(f"âœ… ConfiguraÃ§Ã£o avanÃ§ada executada!")
        print(f"ğŸ¯ Fontes de dados utilizadas:")
        for fonte in resultado.get('data_sources', []):
            print(f"   - {fonte['fonte_dados']}: {fonte['count']} processos")

    except Exception as e:
        print(f"âŒ Erro configuraÃ§Ã£o avanÃ§ada: {e}")


def exemplo_analise_dados():
    """Exemplo de anÃ¡lise dos dados extraÃ­dos."""
    print("\n=== AnÃ¡lise de Dados ===")

    try:
        import polars as pl

        # Procura por arquivos Parquet gerados
        arquivos_parquet = list(Path(".").glob("exemplo_*.parquet"))

        if not arquivos_parquet:
            print("âš ï¸  Nenhum arquivo de exemplo encontrado. Execute os exemplos anteriores primeiro.")
            return

        # Carrega o primeiro arquivo encontrado
        arquivo = arquivos_parquet[0]
        df = pl.read_parquet(arquivo)

        print(f"ğŸ“Š Analisando arquivo: {arquivo}")
        print(f"ğŸ“ˆ Total de registros: {len(df)}")
        print(f"ğŸ“ Colunas disponÃ­veis: {df.columns}")

        # EstatÃ­sticas bÃ¡sicas
        if len(df) > 0:
            print("\nğŸ” EstatÃ­sticas:")
            print(f"   - Processos Ãºnicos: {df.select('processo_numero').n_unique()}")
            print(f"   - ExtraÃ§Ãµes bem-sucedidas: {df.filter(pl.col('sucesso_extracao') == True).height}")
            print(f"   - Texto mÃ©dio por processo: {df.select('tamanho_texto').mean().item():.0f} caracteres")

            # Fontes de dados
            fontes = df.group_by('fonte_dados').agg(pl.count().alias('count'))
            print(f"\nğŸ“Š Fontes de dados:")
            for row in fontes.iter_rows(named=True):
                print(f"   - {row['fonte_dados']}: {row['count']} processos")

    except ImportError:
        print("âŒ Polars nÃ£o instalado. Use: pip install polars")
    except Exception as e:
        print(f"âŒ Erro na anÃ¡lise: {e}")


def exemplo_recuperacao_checkpoint():
    """Exemplo de recuperaÃ§Ã£o usando checkpoint."""
    print("\n=== RecuperaÃ§Ã£o com Checkpoint ===")

    processos = [f"000{i:04d}-12.2023.1.00.0000" for i in range(1, 51)]  # 50 processos

    scraper = STFScraper(
        process_list=processos,
        output_path="exemplo_checkpoint.parquet",
        batch_size=10,
        checkpoint_interval=5,  # Checkpoint a cada 5 processos
        max_retries=2
    )

    try:
        print("ğŸš€ Iniciando processamento com checkpoint...")
        resultado = scraper.run()

        print(f"âœ… Checkpoint concluÃ­do!")
        print(f"ğŸ’¾ Arquivo final: {resultado.get('output_path')}")

        # Se executar novamente, deve continuar de onde parou
        print("\nğŸ”„ Executando novamente (deve pular processos jÃ¡ feitos)...")
        scraper2 = STFScraper(
            process_list=processos,  # Mesma lista
            output_path="exemplo_checkpoint.parquet",  # Mesmo arquivo
            batch_size=10
        )

        resultado2 = scraper2.run()
        print(f"âœ… Segunda execuÃ§Ã£o: {resultado2.get('from_cache', 0)} processos vindos do cache")

    except Exception as e:
        print(f"âŒ Erro checkpoint: {e}")


def limpar_arquivos_exemplo():
    """Remove arquivos de exemplo gerados."""
    print("\nğŸ§¹ Limpando arquivos de exemplo...")

    padroes = ["exemplo_*.parquet", "*_checkpoint.json"]
    removidos = 0

    for padrao in padroes:
        for arquivo in Path(".").glob(padrao):
            try:
                arquivo.unlink()
                removidos += 1
                print(f"   ğŸ—‘ï¸  Removido: {arquivo}")
            except Exception as e:
                print(f"   âŒ Erro ao remover {arquivo}: {e}")

    print(f"âœ… {removidos} arquivos removidos")


def main():
    """FunÃ§Ã£o principal dos exemplos."""
    print("ğŸš€ STF Scraper - Exemplos de Uso")
    print("=" * 50)

    # Executa exemplos em sequÃªncia
    exemplo_basico()
    exemplo_com_s3()
    exemplo_com_proxies()
    exemplo_configuracao_avancada()
    exemplo_analise_dados()
    exemplo_recuperacao_checkpoint()

    # Pergunta se deve limpar arquivos
    resposta = input("\nğŸ§¹ Deseja limpar arquivos de exemplo? (s/n): ")
    if resposta.lower() in ['s', 'sim', 'y', 'yes']:
        limpar_arquivos_exemplo()

    print("\nâœ… Exemplos concluÃ­dos!")
    print("ğŸ“š Consulte a documentaÃ§Ã£o para mais detalhes: https://stf-scraper.readthedocs.io/")


if __name__ == "__main__":
    main()
